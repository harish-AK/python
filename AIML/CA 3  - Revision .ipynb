{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be4300c-c2fa-4771-8ba9-d69809ca968e",
   "metadata": {},
   "source": [
    "Linear Regression - Theory, example, code [done]\n",
    "Multiple linear regression - code [done]\n",
    "Lasso/Ridge - THeory, Code [done]\n",
    "Polynomial regression - Theory, code [done]\n",
    "Regression metrices - Theory, example, code [done]\n",
    "Logistic regression - code [done]\n",
    "\n",
    "Decision tree - Theory, example, code [done]\n",
    "KNN - Theory, example, code [done]\n",
    "Classification matrix - code, example, code [done]\n",
    "Gradient descent - Theory, example [done]\n",
    "Naive bayes - Theory, example, code [done]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763fe9d2-db7b-4b9f-8c27-68680cc0d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12. 14. 16.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Linear regression\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# regression metrices\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# R-squared\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Logistic\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # take a word, if its occurs less than or equal to 1000 times\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "X_train_tfidf.shape,X_test_tfidf.shape\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_tfidf, y_train)\n",
    "predictions = logistic_model.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "\n",
    "# Ridge\n",
    "ridge = Ridge(alpha= 1)\n",
    "ridge.fit(x_train_scaled,y_train)\n",
    "\n",
    "# Lasso\n",
    "lasso = Lasso(alpha= 1)\n",
    "lasso.fit(x_train_scaled,y_train)\n",
    "\n",
    "# Decision tree\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Gradient descent\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2 * X + 1 + 0.1 * np.random.randn(100, 1)\n",
    "\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# Gradient Descent\n",
    "for i in range(iterations):\n",
    "    gradients = 2/len(X) * X.T.dot(X.dot(theta) - y)\n",
    "    theta = theta - learning_rate * gradients\n",
    "\n",
    "print(\"Optimal theta:\", theta)\n",
    "\n",
    "# Naive bayes\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcdef16-5143-4fce-8a4d-a8a04f5fbaa3",
   "metadata": {},
   "source": [
    "Linear Regression:\n",
    "Definition: Linear Regression is a statistical method used for modeling the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship and aims to find the best-fit line that minimizes the sum of squared differences between observed and predicted values.\n",
    "\n",
    "Multiple Linear Regression:\n",
    "Definition: Multiple Linear Regression is an extension of linear regression to multiple independent variables. Instead of predicting the outcome based on one variable, it predicts the outcome using two or more variables.\n",
    "\n",
    "Lasso/Ridge Regression:\n",
    "Definition: Lasso (Least Absolute Shrinkage and Selection Operator) and Ridge Regression are forms of linear regression that include regularization terms to prevent overfitting. Lasso adds the absolute values of the coefficients to the cost function, while Ridge adds the squared values. Both methods help in feature selection and controlling the complexity of the model.\n",
    "\n",
    "Polynomial Regression:\n",
    "Definition: Polynomial Regression is a type of regression that models the relationship between the independent variable and the dependent variable as an nth-degree polynomial. It allows capturing non-linear relationships in the data.\n",
    "\n",
    "Regression Metrics:\n",
    "Definition: Regression metrics are used to evaluate the performance of regression models. Common metrics include Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared. These metrics quantify the accuracy and goodness of fit of the model.\n",
    "\n",
    "Logistic Regression:\n",
    "Definition: Logistic Regression is a classification algorithm used for binary and multiclass classification problems. Despite its name, it's used for classification, not regression. It models the probability of an instance belonging to a particular class using the logistic function.\n",
    "\n",
    "Decision Tree:\n",
    "Definition: A Decision Tree is a supervised machine learning algorithm used for classification and regression. It recursively splits the dataset based on features to create a tree-like structure, where leaves represent the predicted outcome.\n",
    "\n",
    "K-Nearest Neighbors (KNN):\n",
    "Definition: K-Nearest Neighbors is a simple and effective classification algorithm. It classifies a new data point based on the majority class of its k-nearest neighbors in the feature space.\n",
    "\n",
    "Classification Matrix:\n",
    "Definition: A Classification Matrix, also known as a confusion matrix, is a table that describes the performance of a classification model. It shows the counts of true positives, true negatives, false positives, and false negatives. From this matrix, various metrics like accuracy, precision, recall, and F1-score can be derived.\n",
    "\n",
    "Gradient Descent:\n",
    "Definition: Gradient Descent is an optimization algorithm used to minimize the cost function in machine learning models. It iteratively adjusts the model parameters in the direction of the steepest decrease in the cost function to find the optimal values.\n",
    "\n",
    "Naive Bayes:\n",
    "Definition: Naive Bayes is a probabilistic classification algorithm based on Bayes' theorem. It assumes independence among features, making computations more manageable. It is widely used in text classification, spam filtering, and other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e658f1-1f89-4def-a887-c41d1da380fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f481c-e437-408a-aa37-ff8e5adc82f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f14da5-db08-4790-b523-7f72a93f4baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebee802-2010-472b-a405-0da88414de06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
